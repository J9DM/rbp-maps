{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plot_features:starting program\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import memory_profiler\n",
    "outdir = '/home/bay001/projects/maps_20160420/analysis/tests/'\n",
    "logger = logging.getLogger('plot_features')\n",
    "logger.setLevel(logging.INFO)\n",
    "ih = logging.FileHandler(os.path.join(outdir,'log.txt'))\n",
    "eh = logging.FileHandler(os.path.join(outdir,'log.err'))\n",
    "ih.setLevel(logging.INFO)\n",
    "eh.setLevel(logging.ERROR)\n",
    "logger.addHandler(ih)\n",
    "logger.addHandler(eh)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ih.setFormatter(formatter)\n",
    "eh.setFormatter(formatter)\n",
    "logger.info(\"starting program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Created on Sep 21, 2016\n",
    "\n",
    "@author: brian\n",
    "'''\n",
    "import pybedtools as bt\n",
    "\n",
    "class Feature():\n",
    "    '''\n",
    "    classdocs\n",
    "    '''\n",
    "\n",
    "\n",
    "    def __init__(self, annotation, source):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        self.annotation = annotation.rstrip()\n",
    "        self.source = source\n",
    "\n",
    "    def get_bedtool(self):\n",
    "        if(self.source == 'bed'):\n",
    "            chrom, start, end, name, score, strand = self.annotation.split('\\t')\n",
    "        return bt.create_interval_from_list([chrom,\n",
    "                                             start,\n",
    "                                             end,\n",
    "                                             name,\n",
    "                                             score,\n",
    "                                             strand])\n",
    "\n",
    "class SkippedExonFeature():\n",
    "    def __init__(self, annotation, source):\n",
    "        self.source = source\n",
    "        self.annotation = annotation.rstrip()\n",
    "    def get_bedtools(self):\n",
    "        if(self.source == 'miso'):\n",
    "            event = self.annotation.split('\\t')[0]\n",
    "            up, se, down = event.split('@')\n",
    "            \n",
    "            chrom, start, stop, strand = up.split(':')\n",
    "            up = bt.create_interval_from_list([chrom, int(start)-1, stop, '0', '0', strand])\n",
    "            \n",
    "            chrom, start, stop, strand = se.split(':')\n",
    "            se = bt.create_interval_from_list([chrom, int(start)-1, stop, '0', '0', strand])\n",
    "            \n",
    "            chrom, start, stop, strand = down.split(':')\n",
    "            down = bt.create_interval_from_list([chrom, int(start)-1, stop, '0', '0', strand])\n",
    "        elif(self.source == 'hta2_0'):\n",
    "            pass\n",
    "        elif(self.source == 'xintao'):\n",
    "            pass\n",
    "        elif(self.source == 'eric'):\n",
    "            name, se = self.annotation.split(';')\n",
    "            xintao, ericleft, ericright = se.split('||')\n",
    "            upstream_es = 1\n",
    "            downstream_es = 250000000\n",
    "            if(\"Not_found\") not in ericleft:\n",
    "                upstream_es = ericleft.split(':')[2].split('-')[0]\n",
    "            if(\"Not_found\") not in ericright:\n",
    "                downstream_ee = ericright.split(':')[2].split('-')[1]\n",
    "            \n",
    "            event, chrom, upstream, downstream, strand = xintao.split(':')\n",
    "            upstream_ee, skipped_es = upstream.split('-')\n",
    "            skipped_ee, downstream_es = downstream.split('-')\n",
    "            \n",
    "            se = bt.create_interval_from_list([chrom, skipped_es, skipped_ee, '0', '0', strand])\n",
    "            if(strand == '+'):\n",
    "                up = bt.create_interval_from_list([chrom, upstream_es, upstream_ee, '0', '0', strand])\n",
    "                down = bt.create_interval_from_list([chrom, downstream_es, downstream_ee, '0', '0', strand])\n",
    "            elif(strand == '-'):\n",
    "                up = bt.create_interval_from_list([chrom, downstream_es, downstream_ee, '0', '0', strand])\n",
    "                down = bt.create_interval_from_list([chrom, upstream_es, upstream_ee, '0', '0', strand])\n",
    "        elif(self.source == 'rmats'):\n",
    "            id, GeneID, geneSymbol, chrom, strand, \\\n",
    "            exonStart_0base, exonEnd, \\\n",
    "            upstreamES, upstreamEE, \\\n",
    "            downstreamES, downstreamEE, \\\n",
    "            ID1, IJC_SAMPLE_1, SJC_SAMPLE_1, \\\n",
    "            IJC_SAMPLE_2, SJC_SAMPLE_2, \\\n",
    "            IncFormLen, SkipFormLen, PValue, \\\n",
    "            FDR, IncLevel1, IncLevel2, IncLevelDifference = self.annotation.split('\\t')\n",
    "            \n",
    "            se = bt.create_interval_from_list([chrom, exonStart_0base, exonEnd, '0', '0', strand])\n",
    "            if(strand == '+'):\n",
    "                up = bt.create_interval_from_list([chrom, upstreamES, upstreamEE, '0', '0', strand])\n",
    "                down = bt.create_interval_from_list([chrom, downstreamES, downstreamEE, '0', '0', strand])\n",
    "            elif(strand == '-'):\n",
    "                down = bt.create_interval_from_list([chrom, upstreamES, upstreamEE, '0', '0', strand])\n",
    "                up = bt.create_interval_from_list([chrom, downstreamES, downstreamEE, '0', '0', strand])\n",
    "            else:\n",
    "                print(\"Warning, strand not correct!\")\n",
    "                return -1\n",
    "        return up, se, down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def five_prime_site(rbp,                # type: ReadDensity\n",
    "                    upstream_interval,  # type: BedTools.Interval\n",
    "                    interval,           # type: BedTools.Interval\n",
    "                    exon_offset,        # type: int\n",
    "                    intron_offset,      # type: int\n",
    "                    trunc = True):      # type: boolean\n",
    "    # type: (...) -> (int, list, int)\n",
    "    '''\n",
    "    Given an upstream exon and a focus exon, return a list of density \n",
    "    values of the surrounding 5' intron/exon boundary given \n",
    "    exon_offset and intron_offset parameters. Also returns the \n",
    "    list of padded values which can be appended to either end of\n",
    "    the returned list in order to conform to a uniform length. \n",
    "    \n",
    "    Args:\n",
    "        rbp: ReadDensity object containing *.pos and *.neg bigwig files\n",
    "        upstream interval: Interval describing an exon/feature upstream of\n",
    "            the current feature.\n",
    "        interval: The focus interval/exon.\n",
    "        exon_offset: the number of nt from the 5' Exon boundary into the exon.\n",
    "        intron_offset: the number of nt from the 5' Exon boundary into the intron.\n",
    "        trunc: if trunc is True, then consider instances where \n",
    "            exon_offset > length of the exon.\n",
    "    Returns: \n",
    "        fivep_pad: if the desired wiggle length is X but the returned wiggle \n",
    "            does not span the entire length, return N where N is the number\n",
    "            of upstream positions that will need to be filled for len(wiggle)=X.\n",
    "            E.G. exon_offset+intron_offset = 10.\n",
    "                fivep_pad = 3: NNN1111111\n",
    "        wiggle: list of densities given a region.\n",
    "        threep_pad: if the desired wiggle length is X but the returned wiggle \n",
    "            does not span the entire length, return N where N is the number\n",
    "            of downstream positions that will need to be filled for len(wiggle)=X.\n",
    "            E.G. exon_offset+intron_offset = 10.\n",
    "                threep_pad = 3: 1111111NNN\n",
    "    '''\n",
    "    exon = exon_offset\n",
    "    intron = intron_offset\n",
    "    \n",
    "    fivep_pad = 0\n",
    "    threep_pad = 0\n",
    "    # [    ]-----|-----[2  |  |  8]-----|----[10   15]\n",
    "    if interval.strand == \"+\":\n",
    "        if(trunc == True):\n",
    "            if interval.start + exon_offset > interval.end:\n",
    "                # middle = int((interval.end + interval.start)/2)\n",
    "                # exon_offset = interval.end - middle\n",
    "                exon_offset = interval.end - interval.start\n",
    "                threep_pad = exon - exon_offset\n",
    "            if interval.start - intron_offset < upstream_interval.end:\n",
    "                intron_offset = interval.start - upstream_interval.end\n",
    "                # middle = int((interval.start + upstream_interval.end)/2)\n",
    "                # intron_offset = interval.start - middle\n",
    "                fivep_pad = intron - intron_offset\n",
    "        wiggle = rbp.values(interval.chrom, (interval.start - intron_offset), (interval.start + exon_offset), interval.strand)\n",
    "    elif interval.strand == \"-\":\n",
    "        if(trunc == True):\n",
    "            if interval.end - exon_offset < interval.start:\n",
    "                # middle = int((interval.start + interval.end)/2)\n",
    "                # exon_offset = interval.end - middle\n",
    "                exon_offset = interval.end - interval.start\n",
    "                threep_pad = exon - exon_offset\n",
    "            if interval.end + intron_offset > upstream_interval.start:\n",
    "                intron_offset = upstream_interval.start - interval.end\n",
    "                # middle = int((upstream_interval.start + interval.end)/2)\n",
    "                # intron_offset = upstream_interval.start - middle\n",
    "                fivep_pad = intron - intron_offset\n",
    "                \n",
    "        wiggle = rbp.values(interval.chrom, (interval.end - exon_offset), (interval.end + intron_offset), interval.strand)\n",
    "    return fivep_pad, wiggle, threep_pad\n",
    "\n",
    "def three_prime_site(rbp,                   # type: ReadDensity\n",
    "                     downstream_interval,   # type: BedTools.Interval\n",
    "                     interval,              # type: BedTools.Interval\n",
    "                     exon_offset,           # type: int\n",
    "                     intron_offset,         # type: int\n",
    "                     trunc = True):         # type: Boolean\n",
    "    # [      ]-----|-----[   |   ]-----|----[   ]\n",
    "    # type: (...) -> (int, list, int)\n",
    "    '''\n",
    "    Given an downstream exon and a focus exon, return a list of density \n",
    "    values of the surrounding 3' intron/exon boundary given \n",
    "    exon_offset and intron_offset parameters. Also returns the \n",
    "    list of padded values which can be appended to either end of\n",
    "    the returned list in order to conform to a uniform length. \n",
    "    \n",
    "    Args:\n",
    "        rbp: ReadDensity object containing *.pos and *.neg bigwig files\n",
    "        upstream interval: Interval describing an exon/feature upstream of\n",
    "            the current feature.\n",
    "        interval: The focus interval/exon.\n",
    "        exon_offset: the number of nt from the 5' Exon boundary into the exon.\n",
    "        intron_offset: the number of nt from the 5' Exon boundary into the intron.\n",
    "        trunc: if trunc is True, then consider instances where \n",
    "            exon_offset > length of the exon.\n",
    "    Returns: \n",
    "        fivep_pad: if the desired wiggle length is X but the returned wiggle \n",
    "            does not span the entire length, return N where N is the number\n",
    "            of upstream positions that will need to be filled for len(wiggle)=X.\n",
    "            E.G. exon_offset+intron_offset = 10.\n",
    "                fivep_pad = 3: NNN1111111\n",
    "        wiggle: list of densities given a region.\n",
    "        threep_pad: if the desired wiggle length is X but the returned wiggle \n",
    "            does not span the entire length, return N where N is the number\n",
    "            of downstream positions that will need to be filled for len(wiggle)=X.\n",
    "            E.G. exon_offset+intron_offset = 10.\n",
    "                threep_pad = 3: 1111111NNN\n",
    "    '''\n",
    "    exon = exon_offset\n",
    "    intron = intron_offset\n",
    "    \n",
    "    fivep_pad = 0\n",
    "    threep_pad = 0\n",
    "    \n",
    "    if interval.strand == \"+\":\n",
    "        if(trunc == True):\n",
    "            if interval.end - exon_offset < interval.start:\n",
    "                # middle = int((interval.start + interval.end)/2)\n",
    "                # exon_offset = interval.end - middle\n",
    "                exon_offset = interval.end - interval.start\n",
    "                fivep_pad = exon - exon_offset\n",
    "            if interval.end + intron_offset > downstream_interval.start:\n",
    "                # middle = int((interval.end + downstream_interval.start)/2)\n",
    "                # intron_offset = downstream_interval.start - middle\n",
    "                intron_offset = downstream_interval.start - interval.end\n",
    "                threep_pad = intron - intron_offset\n",
    "        wiggle = rbp.values(interval.chrom, interval.end - exon_offset, interval.end + intron_offset, interval.strand)\n",
    "    elif interval.strand == \"-\":\n",
    "        if(trunc == True):\n",
    "            if interval.start + exon_offset > interval.end:\n",
    "                # middle = int((interval.start + interval.end)/2)\n",
    "                # exon_offset = interval.end - middle\n",
    "                exon_offset = interval.end - interval.start\n",
    "                fivep_pad = exon - exon_offset\n",
    "            if interval.start - intron_offset < downstream_interval.end:\n",
    "                # middle = int((interval.start + downstream_interval.end)/2)\n",
    "                # intron_offset = interval.start - middle\n",
    "                intron_offset = interval.start - downstream_interval.end\n",
    "                threep_pad = intron - intron_offset\n",
    "        wiggle = rbp.values(interval.chrom, interval.start - intron_offset, interval.start + exon_offset, interval.strand)\n",
    "    return fivep_pad, wiggle, threep_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(density):\n",
    "    \"\"\"\n",
    "    These functions expect a dataframe with density values (columns)\n",
    "    across a number of regions (rows). These dataframes may also contain\n",
    "    information regarding premature boundaries for each region (marked as -1)\n",
    "    and no-density regions (marked by nan). This cleans the dataframe.\n",
    "    \"\"\"\n",
    "    density = density.fillna(0) # NaNs are regions which contain zero density\n",
    "    return density.replace(-1, np.nan) # -1 are regions which should not be counted at all\n",
    "\n",
    "def remove_outliers(rbpdataframe, conf = 0.95):\n",
    "    logger.info(\"Removing outliers (keep {})\".format(conf))\n",
    "    means = list()\n",
    "    sems = list()\n",
    "    for key, value in rbpdataframe.iteritems():\n",
    "        df = rbpdataframe[key].dropna()\n",
    "        \n",
    "        nums = len(df)\n",
    "        droppercent = (1-conf)/2.0\n",
    "        dropnum = int(nums*(droppercent))\n",
    "        df = df.sort_values()\n",
    "        if(dropnum>0):\n",
    "            df = df[dropnum:-dropnum]\n",
    "        \n",
    "        means.append(df.mean())\n",
    "        sems.append(df.sem())\n",
    "    logger.info(\"Finished removing outliers (keep {})\".format(conf))\n",
    "    return means, sems\n",
    "\n",
    "def normalize_and_per_region_subtract(density, input_density, \n",
    "                                      pseudocount, ipseudocount, \n",
    "                                      min_density_threshold = 0):\n",
    "    \"\"\"\n",
    "    Normalizes ip matrix of m x n (where m is the row of each event in a feature,\n",
    "    and n is the column relating to nucleotide position). \n",
    "    \"\"\"\n",
    "    logger.info(\"Starting normalization (per region subtraction)\")\n",
    "    df_indices = density.index\n",
    "    dfi_indices = input_density.index\n",
    "    missing = set(df_indices) - set(dfi_indices)\n",
    "    \n",
    "    input_density = input_density.append(input_density.ix[missing])\n",
    "    \n",
    "    pdf = calculate_pdf(density, pseudocount, min_density_threshold)\n",
    "    # pdf.to_csv('/Users/brianyee/git/encode/encode/rbpmaps/testfiles/rbfox2/outputs/ip_pdf.csv')\n",
    "    pdfi = calculate_pdf(input_density, ipseudocount, min_density_threshold)\n",
    "    # pdfi.to_csv('/Users/brianyee/git/encode/encode/rbpmaps/testfiles/rbfox2/outputs/input_pdf.csv')\n",
    "    subtracted = pdf.sub(pdfi)\n",
    "    logger.info(\"Starting normalization (per region subtraction)\")\n",
    "    return subtracted\n",
    "\n",
    "def calculate_pdf(density, pseudocount = None, min_density_threshold = 0):\n",
    "    \"\"\"\n",
    "    Calculates the PDF of a density matrix.\n",
    "    Logic:\n",
    "    \n",
    "    Args: \n",
    "        density (pandas.DataFrame) : r x c matrix of densities. May contain\n",
    "            NaN corresponding to values in which no density was returned.\n",
    "            These values should be counted.\n",
    "            May contain -1 corresponding to values in which a particular\n",
    "            region is shorter than the full DataFrame length. These \n",
    "            values should not be counted.\n",
    "        min_density_threshold (integer) : minimum total density across\n",
    "            a row. (Deprecated - may be removed in the future)\n",
    "    \n",
    "    Returns:\n",
    "        pdf (pandas.DataFrame) : r x c matrix of densities normalized\n",
    "            across each respective (r)ow as a probability density func.\n",
    "    \"\"\"\n",
    "    df = clean(density)\n",
    "    min_read = pseudocount if pseudocount else min([item for item in df.unstack().values if item > 0])\n",
    "\n",
    "    df = df + min_read\n",
    "    pdf = df.div(df.sum(axis=1), axis=0)\n",
    "    return pdf # , mean, sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        three_upstream = pd.DataFrame(three_upstream).T\\n        five_skipped = pd.DataFrame(five_skipped).T\\n        three_skipped = pd.DataFrame(three_skipped).T\\n        five_downstream = pd.DataFrame(five_downstream).T\\n    logger.info(\"Finished matrix creation: {}, {}, {}, {}\".format(three_upstream.shape[0],\\n                                                                  five_skipped.shape[0],\\n                                                                  three_skipped.shape[0],\\n                                                                  five_downstream.shape[0]))\\n    if combine_regions == False:\\n        return three_upstream, five_skipped, three_skipped, five_downstream\\n    else:\\n        ra = pd.concat([three_upstream,five_skipped,three_skipped,five_downstream],axis=1)\\n        ra.columns = range(0,ra.shape[1])\\n        return ra'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_se_matrix(annotation, density, exon_offset, intron_offset, is_scaled, combine_regions=True, annotation_type=\"rmats\"):\n",
    "    \"\"\"\n",
    "    Creates an r x c pandas dataframe of r events for a skipped\n",
    "    exon feature. An SE matrix will contain four distinct regions: \n",
    "    \n",
    "    |_]----||----[__||__]----||----[_|\n",
    "    \n",
    "    - the [..exon_offset]--intron_offset--... 3' site of an upstream exon\n",
    "    - the ...--intron_offset--[exon_offset..] 5' site of the upstream skipped exon\n",
    "    - the [..exon_offset]--intron_offset--... 3' site of the downstream skipped exon\n",
    "    - the ..--intron_offset--[exon_offset..] 5' site of the downstream exon\n",
    "    Args:\n",
    "        annotation (string) : path of file containing the annotation\n",
    "        density (ReadDensity) : object containing positive and negative BigWig files\n",
    "        exon_offset (integer) : how far into the exon boundary to plot\n",
    "        intron_offset (integer) : how far after the exon boundary to plot\n",
    "        is_scaled (boolean) : if all features are of different length, this must be true\n",
    "            to resize all features to fit on a 0-100% scale.\n",
    "        combine_regions (boolean) : if False, return four DataFrames instead of one.\n",
    "        annotation_type (string) : may be rmats format or any additional defined format in Feature\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame : a dataframe of r events for an SE feature.\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting SE matrix creation [ANNOTATION:{},DENSITY:{},UP:{},DOWN:{},SCALED:{},TYPE:{}\".format(\n",
    "                                                                                                            annotation,\n",
    "                                                                                                            density.name,\n",
    "                                                                                                            exon_offset,\n",
    "                                                                                                            intron_offset,\n",
    "                                                                                                            is_scaled,\n",
    "                                                                                                            annotation_type))\n",
    "    three_upstream = {}\n",
    "    five_skipped = {}\n",
    "    three_skipped = {}\n",
    "    five_downstream = {}\n",
    "    \n",
    "    with open(annotation) as f:\n",
    "        for line in f:\n",
    "            if not line.startswith('event_name') and not line.startswith('ID'):\n",
    "                event = line.rstrip()\n",
    "                upstream_interval, interval, downstream_interval = SkippedExonFeature(event,annotation_type).get_bedtools()\n",
    "                \n",
    "                \"\"\"three prime upstream region\"\"\"\n",
    "                left_pad, wiggle, right_pad = three_prime_site(density, \n",
    "                                                                        interval,\n",
    "                                                                        upstream_interval,\n",
    "                                                                        exon_offset,\n",
    "                                                                        intron_offset)\n",
    "                wiggle = pd.Series(wiggle)\n",
    "                wiggle = abs(wiggle) # convert all values to positive\n",
    "        \n",
    "                wiggle = np.pad(wiggle,(left_pad,right_pad),'constant',constant_values=(-1))\n",
    "                wiggle = np.nan_to_num(wiggle) \n",
    "\n",
    "                three_upstream[event] = wiggle\n",
    "                \"\"\"five prime site of skipped region\"\"\"\n",
    "                left_pad, wiggle, right_pad = five_prime_site(density, \n",
    "                                                                        upstream_interval,\n",
    "                                                                        interval,\n",
    "                                                                        exon_offset,\n",
    "                                                                        intron_offset)\n",
    "                \n",
    "                wiggle = pd.Series(wiggle)\n",
    "                wiggle = abs(wiggle) # convert all values to positive\n",
    "                wiggle = np.pad(wiggle,(left_pad,right_pad),'constant',constant_values=(-1))\n",
    "                wiggle = np.nan_to_num(wiggle)\n",
    "                five_skipped[event] = wiggle\n",
    "                \"\"\"three prime site of skipped region\"\"\"\n",
    "                left_pad, wiggle, right_pad = three_prime_site(density, \n",
    "                                                                         downstream_interval,\n",
    "                                                                         interval,\n",
    "                                                                         exon_offset,\n",
    "                                                                         intron_offset)\n",
    "                wiggle = pd.Series(wiggle)\n",
    "                wiggle = abs(wiggle) # convert all values to positive\n",
    "                wiggle = np.pad(wiggle,(left_pad,right_pad),'constant',constant_values=(-1))\n",
    "                wiggle = np.nan_to_num(wiggle) #\n",
    "                three_skipped[event] = wiggle\n",
    "                \"\"\"five prime site of downstream region\"\"\"\n",
    "                left_pad, wiggle, right_pad = five_prime_site(density, \n",
    "                                                                        interval,\n",
    "                                                                        downstream_interval,\n",
    "                                                                        exon_offset,\n",
    "                                                                        intron_offset)\n",
    "                wiggle = pd.Series(wiggle)\n",
    "                wiggle = abs(wiggle) # convert all values to positive\n",
    "                wiggle = np.pad(wiggle,(left_pad,right_pad),'constant',constant_values=(-1))\n",
    "                wiggle = np.nan_to_num(wiggle) # convert all nans to 0\n",
    "                five_downstream[event] = wiggle\n",
    "\n",
    "        three_upstream = pd.DataFrame(three_upstream).T\n",
    "        five_skipped = pd.DataFrame(five_skipped).T\n",
    "        three_skipped = pd.DataFrame(three_skipped).T\n",
    "        five_downstream = pd.DataFrame(five_downstream).T\n",
    "    logger.info(\"Finished matrix creation: {}, {}, {}, {}\".format(three_upstream.shape[0],\n",
    "                                                                  five_skipped.shape[0],\n",
    "                                                                  three_skipped.shape[0],\n",
    "                                                                  five_downstream.shape[0]))\n",
    "    if combine_regions == False:\n",
    "        return three_upstream, five_skipped, three_skipped, five_downstream\n",
    "    else:\n",
    "        ra = pd.concat([three_upstream,five_skipped,three_skipped,five_downstream],axis=1)\n",
    "        ra.columns = range(0,ra.shape[1])\n",
    "        return ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Created on Jun 27, 2016\n",
    "\n",
    "@author: brianyee\n",
    "'''\n",
    "\n",
    "# import matrix_functions as mtx\n",
    "# import normalization_functions as norm\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "class Map():\n",
    "    \"\"\"\n",
    "    Map class\n",
    "    \n",
    "    Attributes:\n",
    "        self.output_file (string) : output file \n",
    "            (deprecated - we use this to just get output_base instead).\n",
    "        self.log_file (string) : log file \n",
    "        self.name (string) : name of the Map object \n",
    "            (deprecated - will be removed later).\n",
    "        self.is_scaled (boolean) : if regions need to be scaled - \n",
    "            if features are of different length, scale them from 0-100%\n",
    "        self.annotation (string) : annotation file - can be rmats, miso, or\n",
    "            any file whose line is defined in Feature\n",
    "        self.annotation_type (string) : annotation source - can be \n",
    "            'rmats' 'miso' or any filetype defined in Feature\n",
    "        self.left (integer) : left offset \n",
    "            (deprecated - will be removed or renamed 'upstream' later).\n",
    "        self.right (integer) : right offset \n",
    "            (deprecated - will be removed or renamed 'downstream' later). \n",
    "        self.exon_offset (integer) : given an exon boundary how many \n",
    "            bases 'into' the exon to plot \n",
    "            (eg. exon_offset = 3: ------[-----|---]------ if '-'=1nt)\n",
    "        self.intron_offset (integer) : given an intron boundary how many \n",
    "            bases 'outside' the exon to plot \n",
    "            (eg. intron_offset = 4: ------[--------]----|-- if '-'=1nt)\n",
    "        self.density (dictionary{'feature':pandas.DataFrame}) : a dictionary of  \n",
    "            Pandas.DataFrames representing normed or unnormed m x n \n",
    "            matrices where m is the each event within a given feature \n",
    "            and n is the length in nucleotides.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_file,\n",
    "                 name, is_scaled = False, \n",
    "                 annotation = None,\n",
    "                 annotation_type = \"miso\",\n",
    "                 left = 0, right = 0,\n",
    "                 exon_offset = 50, intron_offset = 300):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        self.output_file = output_file\n",
    "        self.output_base = os.path.splitext(output_file)[0]\n",
    "        self.name = name\n",
    "        self.is_scaled = is_scaled\n",
    "        self.annotation = annotation\n",
    "        self.annotation_type = annotation_type\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.exon_offset = exon_offset\n",
    "        self.intron_offset = intron_offset\n",
    "        self.density = {}\n",
    "        \n",
    "    def normalize(self, df):\n",
    "        \"\"\"\n",
    "        Sets the Matrix for a Map\n",
    "        \"\"\"\n",
    "        self.density = df\n",
    "    \n",
    "    def get_density(self):\n",
    "        \"\"\"\n",
    "        Returns the Matrix for a Map\n",
    "        \"\"\"\n",
    "        return self.density\n",
    "\n",
    "class ClipWithInput(Map):\n",
    "    \"\"\"\n",
    "    Clip class. Represents a Clip w/ Input Map\n",
    "    Attributes:\n",
    "        self.ip (ReadDensity.ReadDensity) : ReadDensity of the IP \n",
    "        self.inp (ReadDenstiy.ReadDensity) : ReadDensity of the Input\n",
    "        self.ip_raw_density (dictionary{'feature':pandas.DataFrame}) : a dictionary of  \n",
    "            Pandas.DataFrames representing UNNORMED IP m x n \n",
    "            matrices where m is the each event within a given feature \n",
    "            and n is the length in nucleotides. Each matrix may contain more than one\n",
    "            'feature', for example, one might plot both '3_UTRs' and 'Prox_Introns'\n",
    "            in the same map.\n",
    "        self.inp_raw_density (dictionary{'feature':pandas.DataFrame}) : a dictionary of  \n",
    "            Pandas.DataFrames representing UNNORMED INPUT m x n \n",
    "            matrices where m is the each event within a given feature \n",
    "            and n is the length in nucleotides. Each matrix may contain more than one\n",
    "            'feature', for example, one might plot both '3_UTRs' and 'Prox_Introns'\n",
    "            in the same map.\n",
    "        self.density (dictionary{'feature':pandas.DataFrame}) : a dictionary of  \n",
    "            Pandas.DataFrames representing NORMED m x n \n",
    "            matrices (IP over INPUT) where m is the each event within a given feature \n",
    "            and n is the length in nucleotides. Note: Each feature will be normalized\n",
    "            independently.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ReadDensity, InputReadDensity, output_file,\n",
    "                 name, is_scaled = False, \n",
    "                 annotation = None,\n",
    "                 annotation_type = \"miso\",\n",
    "                 left = 0, right = 0,\n",
    "                 exon_offset = 50, intron_offset = 300):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        \n",
    "        Map.__init__(self, output_file,\n",
    "                     name, is_scaled, \n",
    "                     annotation,\n",
    "                     annotation_type,\n",
    "                     left, right,\n",
    "                     exon_offset, intron_offset)\n",
    "        \n",
    "        self.ip = ReadDensity\n",
    "        self.inp = InputReadDensity\n",
    "        \n",
    "        self.ip_raw_density = {}\n",
    "        self.input_raw_density = {}\n",
    "        \n",
    "        self.maptype = \"\"\n",
    "        \n",
    "        self.density = {}\n",
    "        \n",
    "        self.means = list()\n",
    "        self.sems = list()\n",
    "        \n",
    "        self.logger = logging.getLogger('plot_features.Map.ClipWithInput')\n",
    "        self.logger.info('creating an instance of ClipWithDensity')\n",
    "        \n",
    "    def get_means(self):\n",
    "        \"\"\"\n",
    "        Returns the mean densities as Series\n",
    "        \"\"\"\n",
    "        return pd.Series(self.means)\n",
    "    \n",
    "    def get_sems(self):\n",
    "        \"\"\"\n",
    "        Returns standard error as Series\n",
    "        \"\"\"\n",
    "        return pd.Series(self.sems)\n",
    "    \n",
    "    def set_annotation(self,annotation_file):\n",
    "        \"\"\"\n",
    "        Sets the annotation source file\n",
    "        Args:\n",
    "            annotation_file (string) : MISO, RMATS, or any formatted file \n",
    "                defined in Feature.py. \n",
    "        \"\"\"\n",
    "        self.annotation = annotation_file\n",
    "    \n",
    "    def reset_matrix(self):\n",
    "        \"\"\"\n",
    "        Resets all matrices (both raw and normed ip/input) to empty dictionaries\n",
    "        \"\"\"\n",
    "        self.ip_raw_density = {}\n",
    "        self.input_raw_density = {}\n",
    "        self.density = {}\n",
    "            \n",
    "    def normalize(self, normfunc = None, min_density_sum = 0, label = \"\"):\n",
    "        \"\"\"\n",
    "        For each feature in the matrix, perform normalization\n",
    "        \n",
    "        Args:\n",
    "            normfunc (function) : a function(pandas.DataFrame, pandas.DataFrame, min_density_sum) \n",
    "                that takes normalizes a Map's ip_raw_density DataFrame, \n",
    "                containing its IP densities, over its input_raw_density \n",
    "                DataFrame, containing its INPUT densities.\n",
    "            min_density_sum (integer) : density sum cutoff for each event to be counted, \n",
    "                passed to normalization function\n",
    "            label (string) : an intermediate file of this normalized matrix is created for each \n",
    "                feature in the matrix. This provides an optional secondary label, useful for\n",
    "                distinguishing 'included', 'excluded', and 'background' matrices, for example.\n",
    "        Writes:\n",
    "            *.normed_matrix.csv : for each key (feature) in a map's density dictionary, \n",
    "                write the full contents of the normalized density matrix.\n",
    "        \"\"\"\n",
    "        \n",
    "        for feature in self.ip_raw_density:\n",
    "            # print(\"starting normalization for key {} {} {}\".format(key, label, datetime.datetime.now().time()))\n",
    "            self.density[feature] = normfunc(self.ip_raw_density[feature],\n",
    "                                             self.input_raw_density[feature], \n",
    "                                             self.ip.pseudocount(),\n",
    "                                             self.inp.pseudocount(),\n",
    "                                             min_density_sum)\n",
    "            self.density[feature].to_csv(\"{}.{}.{}.normed_matrix.csv\".format(self.output_base, label, feature))\n",
    "            # print(\"finished normalization for key {} {} {}\".format(key, label, datetime.datetime.now().time()))\n",
    "    \n",
    "    def set_means_and_sems(self, feature, conf = 0.95):\n",
    "        \"\"\"\n",
    "        Sets the means and standard error values after outlier\n",
    "        removal. Replaces remove_outliers.\n",
    "        \n",
    "        Args:\n",
    "            feature (string) : the feature \n",
    "            conf (float) : keep {conf}% of densities\n",
    "        \n",
    "        \"\"\"\n",
    "        means = list()\n",
    "        sems = list()\n",
    "        for key, value in self.density[feature].iteritems():\n",
    "            df = self.density[feature][key].dropna()\n",
    "            \n",
    "            nums = len(df)\n",
    "            droppercent = (1-conf)/2.0\n",
    "            dropnum = int(nums*(droppercent))\n",
    "            df = df.sort_values()\n",
    "            if(dropnum>0):\n",
    "                df = df[dropnum:-dropnum]\n",
    "            \n",
    "            means.append(df.mean())\n",
    "            sems.append(df.sem())\n",
    "        self.means = means\n",
    "        self.sems = sems\n",
    "                \n",
    "    def create_matrices(self, label=\"\", is_scaled=True):\n",
    "        densities = [self.ip_raw_density, self.input_raw_density]\n",
    "        rbps = [self.ip, self.inp]\n",
    "        self.logger.info(\"Start creating the Matrix - {}\".format(self.name))\n",
    "        for i in range(0,len(densities)):\n",
    "            densities[i]['feature'] = create_matrix(annotation = self.annotation, \n",
    "                                                       density = rbps[i], \n",
    "                                                       upstream_offset = 0, \n",
    "                                                       downstream_offset = 0, \n",
    "                                                       is_scaled = False,\n",
    "                                                       annotation_type = self.annotation_type)\n",
    "        self.logger.info(\"Finished creating the Matrix - {}\".format(self.name))\n",
    "        self.ip_raw_density['feature'].to_csv(\"{}.ip.{}_raw_density_matrix.csv\".format(self.output_base,label))\n",
    "        self.input_raw_density['feature'].to_csv(\"{}.input.{}_raw_density_matrix.csv\".format(self.output_base,label))\n",
    "        self.maptype = label\n",
    "    def create_a3ss_matrices(self, label=\"\"):\n",
    "        densities = [self.ip_raw_density, self.input_raw_density]\n",
    "        rbps = [self.ip, self.inp]\n",
    "        self.logger.info(\"Start creating the A3SS Matrix - {}\".format(self.name))\n",
    "        for i in range(0,len(densities)):\n",
    "            densities[i]['feature'] = create_a3ss_matrix(annotation = self.annotation, \n",
    "                                                               annotation_type = self.annotation_type,\n",
    "                                                               density = rbps[i], \n",
    "                                                               exon_offset = self.exon_offset, \n",
    "                                                               intron_offset = self.intron_offset, \n",
    "                                                               is_scaled = self.is_scaled,\n",
    "                                                               combine_regions = True)\n",
    "        self.logger.info(\"Finished creating the A3SS Matrix - {}\".format(self.name))\n",
    "        self.ip_raw_density['feature'].to_csv(\"{}.ip.{}.{}.a3ss.raw_density_matrix.csv\".format(self.output_base, label, 'feature'))\n",
    "        self.input_raw_density['feature'].to_csv(\"{}.input.{}.{}.a3ss.raw_density_matrix.csv\".format(self.output_base, label, 'feature'))\n",
    "        self.maptype = 'a3ss'\n",
    "    def create_a5ss_matrices(self, label=\"\"):\n",
    "        densities = [self.ip_raw_density, self.input_raw_density]\n",
    "        rbps = [self.ip, self.inp]\n",
    "        self.logger.info(\"Start creating the A5SS Matrix - {}\".format(self.name))\n",
    "        for i in range(0,len(densities)):\n",
    "            densities[i]['feature'] = create_a5ss_matrix(annotation = self.annotation, \n",
    "                                                               annotation_type = self.annotation_type,\n",
    "                                                               density = rbps[i], \n",
    "                                                               exon_offset = self.exon_offset, \n",
    "                                                               intron_offset = self.intron_offset, \n",
    "                                                               is_scaled = self.is_scaled,\n",
    "                                                               combine_regions = True)\n",
    "        self.logger.info(\"Finished creating the A5SS Matrix - {}\".format(self.name))\n",
    "        self.ip_raw_density['feature'].to_csv(\"{}.ip.{}.{}.a5ss.raw_density_matrix.csv\".format(self.output_base, label, 'feature'))\n",
    "        self.input_raw_density['feature'].to_csv(\"{}.input.{}.{}.a5ss.raw_density_matrix.csv\".format(self.output_base, label, 'feature'))\n",
    "        self.maptype = 'a5ss'\n",
    "    def create_mxe_matrices(self, label=\"\"):\n",
    "        densities = [self.ip_raw_density, self.input_raw_density]\n",
    "        rbps = [self.ip, self.inp]\n",
    "        self.logger.info(\"Start creating the MXE Matrix - {}\".format(self.name))\n",
    "        for i in range(0,len(densities)):\n",
    "            \n",
    "            densities[i]['feature'] = create_mxe_matrix(annotation = self.annotation, \n",
    "                                                               annotation_type = self.annotation_type,\n",
    "                                                               density = rbps[i], \n",
    "                                                               exon_offset = self.exon_offset, \n",
    "                                                               intron_offset = self.intron_offset, \n",
    "                                                               is_scaled = self.is_scaled,\n",
    "                                                               combine_regions = True)\n",
    "        self.logger.info(\"Start creating the MXE Matrix - {}\".format(self.name))\n",
    "        self.ip_raw_density['feature'].to_csv(\"{}.ip.{}.{}.mxe.raw_density_matrix.csv\".format(self.output_base, label, 'feature'))\n",
    "        self.input_raw_density['feature'].to_csv(\"{}.input.{}.{}.mxe.raw_density_matrix.csv\".format(self.output_base, label, 'feature'))\n",
    "        self.maptype = 'mxe'\n",
    "    def create_se_matrices(self, label=\"\"):\n",
    "        densities = [self.ip_raw_density, self.input_raw_density]\n",
    "        rbps = [self.ip, self.inp]\n",
    "        self.logger.info(\"Start creating the SE Matrix - {}\".format(self.name))\n",
    "        for i in range(0,len(densities)):\n",
    "            densities[i]['feature'] = create_se_matrix(annotation = self.annotation, \n",
    "                                                             annotation_type = self.annotation_type,\n",
    "                                                             density = rbps[i], \n",
    "                                                             exon_offset = self.exon_offset, \n",
    "                                                             intron_offset = self.intron_offset, \n",
    "                                                             is_scaled = self.is_scaled,\n",
    "                                                             combine_regions = True)\n",
    "        self.logger.info(\"Finished creating the SE Matrix - {}\".format(self.name))\n",
    "        self.ip_raw_density['feature'].to_csv(\"{}.ip.{}.{}.se.raw_density_matrix.csv\".format(self.output_base, label, 'feature'))\n",
    "        self.input_raw_density['feature'].to_csv(\"{}.input.{}.{}.se.raw_density_matrix.csv\".format(self.output_base, label, 'feature'))\n",
    "        self.maptype = 'se'\n",
    "    def create_ri_matrices(self, label=\"\"):\n",
    "        densities = [self.ip_raw_density, self.input_raw_density]\n",
    "        rbps = [self.ip, self.inp]\n",
    "        self.logger.info(\"Start creating the RI Matrix - {}\".format(self.name))\n",
    "        for i in range(0,len(densities)):\n",
    "            densities[i]['feature'] = create_ri_matrix(annotation = self.annotation, \n",
    "                                                             annotation_type = self.annotation_type,\n",
    "                                                             density = rbps[i], \n",
    "                                                             exon_offset = self.exon_offset, \n",
    "                                                             intron_offset = self.intron_offset, \n",
    "                                                             is_scaled = self.is_scaled,\n",
    "                                                             combine_regions = True)\n",
    "        self.logger.info(\"Finished creating the SE Matrix - {}\".format(self.name))\n",
    "        self.ip_raw_density['feature'].to_csv(\"{}.ip.{}.{}.ri.raw_density_matrix.csv\".format(self.output_base, label, 'feature'))\n",
    "        self.input_raw_density['feature'].to_csv(\"{}.input.{}.{}.ri.raw_density_matrix.csv\".format(self.output_base, label, 'feature'))\n",
    "        self.maptype = 'ri'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Created on May 3, 2016\n",
    "\n",
    "@author: Gabe\n",
    "'''\n",
    "import pyBigWig\n",
    "import pysam\n",
    "import numpy as np\n",
    "\n",
    "class ReadDensity():\n",
    "    \"\"\"\n",
    "    ReadDensity class\n",
    "    Attributes:\n",
    "        self.pos(positive *.bw file)\n",
    "        self.neg(negative *.bw file)\n",
    "    \"\"\"\n",
    "    def __init__(self, pos, neg, name = None, bam = None):\n",
    "        try:\n",
    "            self.pos = pyBigWig.open(pos)\n",
    "            self.neg = pyBigWig.open(neg)\n",
    "            self.name = name if name is not None else pos.replace('pos','*').replace('neg','*')\n",
    "            print(bam)\n",
    "            self.bam = pysam.AlignmentFile(bam)\n",
    "        except Exception as e:\n",
    "            print(\"couldn't open the bigwig files!\")\n",
    "            print(e)\n",
    "            return 1\n",
    "    \n",
    "    def pseudocount(self):\n",
    "        return 1000000.0/self.bam.count()\n",
    "        \n",
    "    def values(self, chrom, start, end, strand):\n",
    "        \"\"\"\n",
    "        Given a chromosome coordinate, return a list of values\n",
    "        pertaining to the rbpmaps over each nucleotide position.\n",
    "        Reverse the list if going in the negative strand.\n",
    "        \n",
    "        Args:\n",
    "            chrom (str): (eg. chr1)\n",
    "            start (int): 0-based start (first position in chromosome is 0)\n",
    "            end (int): 1-based end (last position is not included)\n",
    "            strand (char): either '+' or '-'\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if strand == \"+\":\n",
    "                return self.pos.values(chrom, start, end)\n",
    "            elif strand == \"-\":\n",
    "                return list(reversed(self.neg.values(chrom, start, end)))\n",
    "            else:\n",
    "                raise(\"Strand neither + or -\")\n",
    "        except RuntimeError:\n",
    "            # usually occurs when no chromosome exists in the bigwig file\n",
    "            return [np.NaN]*abs(start-end)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plot_features.Map.ClipWithInput:creating an instance of ClipWithDensity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/ps-yeolab3/encode/analysis/encode_v12/204_01_RBFOX2.merged.r2.bam\n",
      "/projects/ps-yeolab3/encode/analysis/encode_v12/RBFOX2-204-INPUT_S2_R1.unassigned.adapterTrim.round2.rmRep.rmDup.sorted.r2.bam\n"
     ]
    }
   ],
   "source": [
    "annotationfile = '/projects/ps-yeolab3/bay001/maps/annotations-0.05-0.1-0.05/RBFOX2-HepG2-SE.txt'\n",
    "pos = '/projects/ps-yeolab3/encode/analysis/encode_v12/204_01_RBFOX2.merged.r2.norm.neg.bw'\n",
    "neg = '/projects/ps-yeolab3/encode/analysis/encode_v12/204_01_RBFOX2.merged.r2.norm.pos.bw'\n",
    "bam = '/projects/ps-yeolab3/encode/analysis/encode_v12/204_01_RBFOX2.merged.r2.bam'\n",
    "\n",
    "ipos = '/projects/ps-yeolab3/encode/analysis/encode_v12/RBFOX2-204-INPUT_S2_R1.unassigned.adapterTrim.round2.rmRep.rmDup.sorted.r2.norm.neg.bw'\n",
    "ineg = '/projects/ps-yeolab3/encode/analysis/encode_v12/RBFOX2-204-INPUT_S2_R1.unassigned.adapterTrim.round2.rmRep.rmDup.sorted.r2.norm.pos.bw'\n",
    "ibam = '/projects/ps-yeolab3/encode/analysis/encode_v12/RBFOX2-204-INPUT_S2_R1.unassigned.adapterTrim.round2.rmRep.rmDup.sorted.r2.bam'\n",
    "\n",
    "\n",
    "clip = ReadDensity(pos,neg,'rbfox2',bam)\n",
    "inputclip = ReadDensity(ipos,ineg,'rbfox2input',ibam)\n",
    "outputfile = '/home/bay001/projects/maps_20160420/analysis/tests/rbfox2test.svg'\n",
    "\n",
    "clipexperiment = ClipWithInput(clip, inputclip, outputfile, 'rbfox2', annotation=annotationfile, annotation_type='rmats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plot_features:Starting SE matrix creation [ANNOTATION:/projects/ps-yeolab3/bay001/maps/annotations-0.05-0.1-0.05/RBFOX2-HepG2-SE.txt,DENSITY:rbfox2,UP:50,DOWN:350,SCALED:False,TYPE:rmats\n",
      "INFO:plot_features:Finished matrix creation: 32823, 32823, 32823, 32823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2244.82 MiB, increment: 709.50 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit create_se_matrix(annotationfile, clip, exon_offset=50, intron_offset=350, is_scaled=False, combine_regions=True, annotation_type=\"rmats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plot_features:Starting SE matrix creation [ANNOTATION:/projects/ps-yeolab3/bay001/maps/annotations-0.05-0.1-0.05/RBFOX2-HepG2-SE.txt,DENSITY:rbfox2,UP:50,DOWN:350,SCALED:False,TYPE:rmats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1544.46 MiB, increment: 8.57 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit create_se_matrix(annotationfile, clip, exon_offset=50, intron_offset=350, is_scaled=False, combine_regions=True, annotation_type=\"rmats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        three_upstream = pd.DataFrame(three_upstream).T\\n        five_skipped = pd.DataFrame(five_skipped).T\\n        three_skipped = pd.DataFrame(three_skipped).T\\n        five_downstream = pd.DataFrame(five_downstream).T\\n    logger.info(\"Finished matrix creation: {}, {}, {}, {}\".format(three_upstream.shape[0],\\n                                                                  five_skipped.shape[0],\\n                                                                  three_skipped.shape[0],\\n                                                                  five_downstream.shape[0]))\\n    if combine_regions == False:\\n        return three_upstream, five_skipped, three_skipped, five_downstream\\n    else:\\n        ra = pd.concat([three_upstream,five_skipped,three_skipped,five_downstream],axis=1)\\n        ra.columns = range(0,ra.shape[1])\\n        return ra\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_se_matrix2(annotation, density, exon_offset, intron_offset, is_scaled, combine_regions=True, annotation_type=\"rmats\"):\n",
    "    \"\"\"\n",
    "    Creates an r x c pandas dataframe of r events for a skipped\n",
    "    exon feature. An SE matrix will contain four distinct regions: \n",
    "    \n",
    "    |_]----||----[__||__]----||----[_|\n",
    "    \n",
    "    - the [..exon_offset]--intron_offset--... 3' site of an upstream exon\n",
    "    - the ...--intron_offset--[exon_offset..] 5' site of the upstream skipped exon\n",
    "    - the [..exon_offset]--intron_offset--... 3' site of the downstream skipped exon\n",
    "    - the ..--intron_offset--[exon_offset..] 5' site of the downstream exon\n",
    "    Args:\n",
    "        annotation (string) : path of file containing the annotation\n",
    "        density (ReadDensity) : object containing positive and negative BigWig files\n",
    "        exon_offset (integer) : how far into the exon boundary to plot\n",
    "        intron_offset (integer) : how far after the exon boundary to plot\n",
    "        is_scaled (boolean) : if all features are of different length, this must be true\n",
    "            to resize all features to fit on a 0-100% scale.\n",
    "        combine_regions (boolean) : if False, return four DataFrames instead of one.\n",
    "        annotation_type (string) : may be rmats format or any additional defined format in Feature\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame : a dataframe of r events for an SE feature.\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting SE matrix creation [ANNOTATION:{},DENSITY:{},UP:{},DOWN:{},SCALED:{},TYPE:{}\".format(\n",
    "                                                                                                            annotation,\n",
    "                                                                                                            density.name,\n",
    "                                                                                                            exon_offset,\n",
    "                                                                                                            intron_offset,\n",
    "                                                                                                            is_scaled,\n",
    "                                                                                                            annotation_type))\n",
    "    three_upstream = pd.DataFrame(columns=range(0,(exon_offset+intron_offset)))\n",
    "    five_skipped = pd.DataFrame(columns=range(0,(exon_offset+intron_offset)))\n",
    "    three_skipped = pd.DataFrame(columns=range(0,(exon_offset+intron_offset)))\n",
    "    five_downstream = pd.DataFrame(columns=range(0,(exon_offset+intron_offset)))\n",
    "    \n",
    "    with open(annotation) as f:\n",
    "        for line in f:\n",
    "            if not line.startswith('event_name') and not line.startswith('ID'):\n",
    "                event = line.rstrip()\n",
    "                upstream_interval, interval, downstream_interval = SkippedExonFeature(event,annotation_type).get_bedtools()\n",
    "                \n",
    "                \"\"\"three prime upstream region\"\"\"\n",
    "                left_pad, wiggle, right_pad = three_prime_site(density, \n",
    "                                                                        interval,\n",
    "                                                                        upstream_interval,\n",
    "                                                                        exon_offset,\n",
    "                                                                        intron_offset)\n",
    "                wiggle = pd.Series(wiggle)\n",
    "                wiggle = abs(wiggle) # convert all values to positive\n",
    "        \n",
    "                wiggle = np.pad(wiggle,(left_pad,right_pad),'constant',constant_values=(-1))\n",
    "                wiggle = np.nan_to_num(wiggle) \n",
    "\n",
    "                three_upstream.ix[event] = wiggle\n",
    "                \"\"\"five prime site of skipped region\"\"\"\n",
    "                left_pad, wiggle, right_pad = five_prime_site(density, \n",
    "                                                                        upstream_interval,\n",
    "                                                                        interval,\n",
    "                                                                        exon_offset,\n",
    "                                                                        intron_offset)\n",
    "                \n",
    "                wiggle = pd.Series(wiggle)\n",
    "                wiggle = abs(wiggle) # convert all values to positive\n",
    "                wiggle = np.pad(wiggle,(left_pad,right_pad),'constant',constant_values=(-1))\n",
    "                wiggle = np.nan_to_num(wiggle)\n",
    "                five_skipped.ix[event] = wiggle\n",
    "                \"\"\"three prime site of skipped region\"\"\"\n",
    "                left_pad, wiggle, right_pad = three_prime_site(density, \n",
    "                                                                         downstream_interval,\n",
    "                                                                         interval,\n",
    "                                                                         exon_offset,\n",
    "                                                                         intron_offset)\n",
    "                wiggle = pd.Series(wiggle)\n",
    "                wiggle = abs(wiggle) # convert all values to positive\n",
    "                wiggle = np.pad(wiggle,(left_pad,right_pad),'constant',constant_values=(-1))\n",
    "                wiggle = np.nan_to_num(wiggle) #\n",
    "                three_skipped.ix[event] = wiggle\n",
    "                \"\"\"five prime site of downstream region\"\"\"\n",
    "                left_pad, wiggle, right_pad = five_prime_site(density, \n",
    "                                                                        interval,\n",
    "                                                                        downstream_interval,\n",
    "                                                                        exon_offset,\n",
    "                                                                        intron_offset)\n",
    "                wiggle = pd.Series(wiggle)\n",
    "                wiggle = abs(wiggle) # convert all values to positive\n",
    "                wiggle = np.pad(wiggle,(left_pad,right_pad),'constant',constant_values=(-1))\n",
    "                wiggle = np.nan_to_num(wiggle) # convert all nans to 0\n",
    "                five_downstream.ix[event] = wiggle\n",
    "\"\"\"\n",
    "        three_upstream = pd.DataFrame(three_upstream).T\n",
    "        five_skipped = pd.DataFrame(five_skipped).T\n",
    "        three_skipped = pd.DataFrame(three_skipped).T\n",
    "        five_downstream = pd.DataFrame(five_downstream).T\n",
    "    logger.info(\"Finished matrix creation: {}, {}, {}, {}\".format(three_upstream.shape[0],\n",
    "                                                                  five_skipped.shape[0],\n",
    "                                                                  three_skipped.shape[0],\n",
    "                                                                  five_downstream.shape[0]))\n",
    "    if combine_regions == False:\n",
    "        return three_upstream, five_skipped, three_skipped, five_downstream\n",
    "    else:\n",
    "        ra = pd.concat([three_upstream,five_skipped,three_skipped,five_downstream],axis=1)\n",
    "        ra.columns = range(0,ra.shape[1])\n",
    "        return ra\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%memit create_se_matrix2(annotationfile, clip, exon_offset=50, intron_offset=300, is_scaled=False, combine_regions=True, annotation_type=\"rmats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%memit create_se_matrix(annotationfile, clip, exon_offset=50, intron_offset=300, is_scaled=False, combine_regions=True, annotation_type=\"rmats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit create_se_matrix2(annotationfile, clip, exon_offset=50, intron_offset=300, is_scaled=False, combine_regions=True, annotation_type=\"rmats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit create_se_matrix(annotationfile, clip, exon_offset=50, intron_offset=300, is_scaled=False, combine_regions=True, annotation_type=\"rmats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
